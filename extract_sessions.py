#!/usr/bin/env python3
import re
import json
import os
import tempfile
import difflib
from bs4 import BeautifulSoup
import requests

def normalize_speaker_spaces(speaker_text):
    """
    ç™ºè¡¨è€…åã®é€£ç¶šã™ã‚‹ã‚¹ãƒšãƒ¼ã‚¹ï¼ˆåŠè§’ãƒ»å…¨è§’ï¼‰ã‚’å…¨è§’ã‚¹ãƒšãƒ¼ã‚¹1ã¤ã«ç½®ãæ›ãˆã‚‹
    """
    if not speaker_text:
        return speaker_text
    
    # é€£ç¶šã™ã‚‹åŠè§’ã‚¹ãƒšãƒ¼ã‚¹ã€å…¨è§’ã‚¹ãƒšãƒ¼ã‚¹ã€æ··åœ¨ã‚’å…¨è§’ã‚¹ãƒšãƒ¼ã‚¹1ã¤ã«ç½®ãæ›ãˆ
    # \s+ ã¯åŠè§’ã‚¹ãƒšãƒ¼ã‚¹ã€ã‚¿ãƒ–ã€æ”¹è¡Œãªã©ã®ç©ºç™½æ–‡å­—
    # ã€€+ ã¯å…¨è§’ã‚¹ãƒšãƒ¼ã‚¹ã®é€£ç¶š
    # [\sã€€]+ ã¯åŠè§’ãƒ»å…¨è§’ã‚¹ãƒšãƒ¼ã‚¹ã®æ··åœ¨ã—ãŸé€£ç¶š
    normalized = re.sub(r'[\sã€€]{2,}', 'ã€€', speaker_text)
    
    return normalized

def extract_sessions_from_html(html_content):
    soup = BeautifulSoup(html_content, 'html.parser')
    
    # ãƒŸãƒ‹ã‚¹ãƒ†ãƒ¼ã‚¸ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’è¦‹ã¤ã‘ã‚‹
    ministage_section = soup.find('div', {'id': 'ministage'})
    if not ministage_section:
        print("ãƒŸãƒ‹ã‚¹ãƒ†ãƒ¼ã‚¸ã‚»ã‚¯ã‚·ãƒ§ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return {}
    
    sessions_data = {}
    
    # å„ã‚¹ãƒ†ãƒ¼ã‚¸ã®ã‚¢ã‚³ãƒ¼ãƒ‡ã‚£ã‚ªãƒ³ã‚’æ¢ã™
    stage_buttons = ministage_section.find_all('button', class_='collapsible_agenda')
    
    for button in stage_buttons:
        stage_name = button.find('span', class_='title_agenda').text.strip()
        print(f"å‡¦ç†ä¸­ã®ã‚¹ãƒ†ãƒ¼ã‚¸: {stage_name}")
        
        # å¯¾è±¡ã®ã‚¹ãƒ†ãƒ¼ã‚¸ã®ã¿å‡¦ç†
        if stage_name not in ['AWS Village Stage', 'Developers on Live', 'Community Stage']:
            continue
            
        sessions_data[stage_name] = {'Day 1': [], 'Day 2': []}
        
        # ã“ã®ã‚¹ãƒ†ãƒ¼ã‚¸ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’å–å¾—
        content_div = button.find_next_sibling('div', class_='contenttable')
        if not content_div:
            continue
            
        # Day 1ã¨Day 2ã®ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’æ¢ã™
        current_day = None
        for element in content_div.find_all(['h2', 'table']):
            if element.name == 'h2':
                if 'Day 1' in element.text:
                    current_day = 'Day 1'
                elif 'Day 2' in element.text:
                    current_day = 'Day 2'
            elif element.name == 'table' and current_day:
                # ãƒ†ãƒ¼ãƒ–ãƒ«ã®è¡Œã‚’å‡¦ç†
                rows = element.find_all('tr')
                for row in rows[1:]:  # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã‚’ã‚¹ã‚­ãƒƒãƒ—
                    cells = row.find_all('td')
                    if len(cells) >= 2:
                        time_cell = cells[0].text.strip()
                        content_cell = cells[1]
                        
                        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¿ã‚¤ãƒˆãƒ«ã‚’æŠ½å‡º
                        title_span = content_cell.find('span', style=lambda x: x and 'font-weight: bold' in x)
                        if title_span:
                            title = title_span.text.strip()
                            
                            # HTMLã®å†…å®¹ã‚’å–å¾—
                            cell_html = str(content_cell)
                            
                            # <br /><br />ã§åˆ†å‰²ã—ã¦ã‚»ãƒƒã‚·ãƒ§ãƒ³æ¦‚è¦ã¨ç™ºè¡¨è€…ã‚’åˆ†é›¢
                            parts = re.split(r'<br\s*/?\s*>\s*<br\s*/?\s*>', cell_html, flags=re.IGNORECASE)
                            
                            description = ""
                            speaker = ""
                            
                            if len(parts) >= 3:
                                # parts[0]: ã‚¿ã‚¤ãƒˆãƒ«éƒ¨åˆ†
                                # parts[1]: æ¦‚è¦éƒ¨åˆ†
                                # parts[2]: ç™ºè¡¨è€…éƒ¨åˆ†
                                
                                # æ¦‚è¦éƒ¨åˆ†ã‹ã‚‰HTMLã‚¿ã‚°ã‚’é™¤å»
                                desc_soup = BeautifulSoup(parts[1], 'html.parser')
                                description = desc_soup.get_text().strip()
                                
                                # ç™ºè¡¨è€…éƒ¨åˆ†ã‚’å‡¦ç†ï¼ˆè¤‡æ•°ç™ºè¡¨è€…å¯¾å¿œï¼‰
                                speaker_soup = BeautifulSoup(parts[2], 'html.parser')
                                speaker_html = str(speaker_soup)
                                
                                # ç™ºè¡¨è€…éƒ¨åˆ†ã‚’<br />ã§åˆ†å‰²
                                speaker_parts = re.split(r'<br\s*/?\s*>', speaker_html, flags=re.IGNORECASE)
                                speakers = []
                                
                                for speaker_part in speaker_parts:
                                    speaker_text = BeautifulSoup(speaker_part, 'html.parser').get_text().strip()
                                    if speaker_text and not speaker_text.startswith('<'):
                                        # AWSã€Amazonã€ä¼šç¤¾åã§å§‹ã¾ã‚‹è¡Œã‚’ç™ºè¡¨è€…ã¨ã—ã¦èªè­˜
                                        if (speaker_text.startswith(('AWS', 'Amazon', 'æ ªå¼ä¼šç¤¾', 'åˆåŒä¼šç¤¾', 'JSR', 'ä¸‰äº•ä½å‹', 'ç‹¬ç«‹è¡Œæ”¿æ³•äºº')) or
                                            'ã€€' in speaker_text or 'æ°' in speaker_text or 'æ§˜' in speaker_text):
                                            # ã‚¹ãƒšãƒ¼ã‚¹ã‚’æ­£è¦åŒ–ã—ã¦ã‹ã‚‰è¿½åŠ 
                                            normalized_speaker = normalize_speaker_spaces(speaker_text)
                                            speakers.append(normalized_speaker)
                                
                                # è¤‡æ•°ç™ºè¡¨è€…ã‚’æ”¹è¡Œã§çµåˆ
                                speaker = '\n'.join(speakers) if speakers else "æœªå®š"
                                
                            elif len(parts) == 2:
                                # parts[0]: ã‚¿ã‚¤ãƒˆãƒ«éƒ¨åˆ†
                                # parts[1]: æ¦‚è¦ã¾ãŸã¯ç™ºè¡¨è€…
                                
                                content_soup = BeautifulSoup(parts[1], 'html.parser')
                                content_text = content_soup.get_text().strip()
                                
                                # å†…å®¹ãŒç™ºè¡¨è€…æƒ…å ±ã‹ã©ã†ã‹ã‚’åˆ¤å®š
                                if content_text.startswith(('AWS', 'Amazon', 'æ ªå¼ä¼šç¤¾', 'åˆåŒä¼šç¤¾', 'JSR', 'ä¸‰äº•ä½å‹', 'ç‹¬ç«‹è¡Œæ”¿æ³•äºº')):
                                    speaker = normalize_speaker_spaces(content_text)
                                    description = "ã‚»ãƒƒã‚·ãƒ§ãƒ³æ¦‚è¦ã¯æº–å‚™ä¸­ã§ã™ã€‚"
                                else:
                                    description = content_text
                                    speaker = "æœªå®š"
                            else:
                                # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†
                                temp_soup = BeautifulSoup(cell_html, 'html.parser')
                                title_span_in_temp = temp_soup.find('span', style=lambda x: x and 'font-weight: bold' in x)
                                if title_span_in_temp:
                                    title_span_in_temp.decompose()
                                
                                remaining_text = temp_soup.get_text().strip()
                                lines = [line.strip() for line in remaining_text.split('\n') if line.strip()]
                                
                                if len(lines) >= 2:
                                    # æœ€å¾Œã®è¡ŒãŒç™ºè¡¨è€…ã€ãã‚Œä»¥å¤–ãŒæ¦‚è¦
                                    speaker = normalize_speaker_spaces(lines[-1])
                                    description = ' '.join(lines[:-1]).strip()
                                elif len(lines) == 1:
                                    if lines[0].startswith(('AWS', 'Amazon', 'æ ªå¼ä¼šç¤¾', 'åˆåŒä¼šç¤¾', 'JSR', 'ä¸‰äº•ä½å‹', 'ç‹¬ç«‹è¡Œæ”¿æ³•äºº')):
                                        speaker = normalize_speaker_spaces(lines[0])
                                        description = "ã‚»ãƒƒã‚·ãƒ§ãƒ³æ¦‚è¦ã¯æº–å‚™ä¸­ã§ã™ã€‚"
                                    else:
                                        description = lines[0]
                                        speaker = "æœªå®š"
                                else:
                                    description = "ã‚»ãƒƒã‚·ãƒ§ãƒ³æ¦‚è¦ã¯æº–å‚™ä¸­ã§ã™ã€‚"
                                    speaker = "æœªå®š"
                            
                            session = {
                                'time': time_cell,
                                'title': title,
                                'description': description,
                                'speaker': speaker
                            }
                            
                            sessions_data[stage_name][current_day].append(session)
                            print(f"  {current_day}: {time_cell} - {title}")
    
    return sessions_data

def filter_session_data(data):
    """
    ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰æ¯”è¼ƒå¯¾è±¡ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®ã¿ã‚’æŠ½å‡ºã™ã‚‹
    æ¯”è¼ƒå¯¾è±¡: time, title, description, speakerï¼ˆx_postã¯é™¤å¤–ï¼‰
    """
    filtered_data = {}
    target_fields = ['time', 'title', 'description', 'speaker']
    
    for stage, days in data.items():
        filtered_data[stage] = {}
        for day, sessions in days.items():
            filtered_data[stage][day] = []
            for session in sessions:
                filtered_session = {}
                for field in target_fields:
                    if field in session:
                        filtered_session[field] = session[field]
                filtered_data[stage][day].append(filtered_session)
    
    return filtered_data

def compare_json_files(old_file, new_file):
    """
    2ã¤ã®JSONãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¯”è¼ƒã—ã¦å·®åˆ†ã‚’è¡¨ç¤ºã™ã‚‹ï¼ˆtime, title, description, speakerã®ã¿ï¼‰
    """
    try:
        with open(old_file, 'r', encoding='utf-8') as f:
            old_data = json.load(f)
        with open(new_file, 'r', encoding='utf-8') as f:
            new_data = json.load(f)
    except FileNotFoundError as e:
        print(f"ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {e}")
        return False
    except json.JSONDecodeError as e:
        print(f"JSONã®è§£æã‚¨ãƒ©ãƒ¼: {e}")
        return False
    
    # æ¯”è¼ƒå¯¾è±¡ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®ã¿ã‚’æŠ½å‡º
    old_filtered = filter_session_data(old_data)
    new_filtered = filter_session_data(new_data)
    
    # JSONã‚’æ•´å½¢ã•ã‚ŒãŸæ–‡å­—åˆ—ã«å¤‰æ›
    old_json_str = json.dumps(old_filtered, ensure_ascii=False, indent=2, sort_keys=True)
    new_json_str = json.dumps(new_filtered, ensure_ascii=False, indent=2, sort_keys=True)
    
    # å·®åˆ†ã‚’è¨ˆç®—
    old_lines = old_json_str.splitlines(keepends=True)
    new_lines = new_json_str.splitlines(keepends=True)
    
    diff = list(difflib.unified_diff(
        old_lines, 
        new_lines, 
        fromfile='ç¾åœ¨ã®sessions.json (time, title, description, speaker)',
        tofile='æ–°ã—ã„sessions.json (time, title, description, speaker)',
        lineterm=''
    ))
    
    if not diff:
        print("âœ… å·®åˆ†ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚sessions.jsonã¯æœ€æ–°ã®çŠ¶æ…‹ã§ã™ã€‚")
        print("   ï¼ˆæ¯”è¼ƒå¯¾è±¡: time, title, description, speakerï¼‰")
        return False
    else:
        print("ğŸ” sessions.jsonã«å·®åˆ†ãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸ:")
        print("   ï¼ˆæ¯”è¼ƒå¯¾è±¡: time, title, description, speakerï¼‰")
        print("=" * 60)
        for line in diff:
            if line.startswith('+++') or line.startswith('---'):
                print(f"\033[1m{line.rstrip()}\033[0m")  # å¤ªå­—
            elif line.startswith('@@'):
                print(f"\033[36m{line.rstrip()}\033[0m")  # ã‚·ã‚¢ãƒ³
            elif line.startswith('+'):
                print(f"\033[32m{line.rstrip()}\033[0m")  # ç·‘ï¼ˆè¿½åŠ ï¼‰
            elif line.startswith('-'):
                print(f"\033[31m{line.rstrip()}\033[0m")  # èµ¤ï¼ˆå‰Šé™¤ï¼‰
            else:
                print(line.rstrip())
        print("=" * 60)
        return True

def analyze_session_changes(old_file, new_file):
    """
    ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±ã®å¤‰æ›´ã‚’è©³ç´°ã«åˆ†æã™ã‚‹ï¼ˆtime, title, description, speakerã®ã¿ï¼‰
    """
    try:
        with open(old_file, 'r', encoding='utf-8') as f:
            old_data = json.load(f)
        with open(new_file, 'r', encoding='utf-8') as f:
            new_data = json.load(f)
    except (FileNotFoundError, json.JSONDecodeError):
        return
    
    # æ¯”è¼ƒå¯¾è±¡ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®ã¿ã‚’æŠ½å‡º
    old_filtered = filter_session_data(old_data)
    new_filtered = filter_session_data(new_data)
    
    print("\nğŸ“Š å¤‰æ›´å†…å®¹ã®è©³ç´°åˆ†æ:")
    print("   ï¼ˆæ¯”è¼ƒå¯¾è±¡: time, title, description, speakerï¼‰")
    print("-" * 40)
    
    # ã‚¹ãƒ†ãƒ¼ã‚¸ã”ã¨ã«æ¯”è¼ƒ
    for stage in set(list(old_filtered.keys()) + list(new_filtered.keys())):
        if stage not in old_filtered:
            print(f"ğŸ†• æ–°ã—ã„ã‚¹ãƒ†ãƒ¼ã‚¸ãŒè¿½åŠ ã•ã‚Œã¾ã—ãŸ: {stage}")
            continue
        elif stage not in new_filtered:
            print(f"ğŸ—‘ï¸  ã‚¹ãƒ†ãƒ¼ã‚¸ãŒå‰Šé™¤ã•ã‚Œã¾ã—ãŸ: {stage}")
            continue
        
        # æ—¥ã”ã¨ã«æ¯”è¼ƒ
        for day in set(list(old_filtered[stage].keys()) + list(new_filtered[stage].keys())):
            if day not in old_filtered[stage]:
                print(f"ğŸ†• {stage} - {day}: æ–°ã—ã„æ—¥ãŒè¿½åŠ ã•ã‚Œã¾ã—ãŸ")
                continue
            elif day not in new_filtered[stage]:
                print(f"ğŸ—‘ï¸  {stage} - {day}: æ—¥ãŒå‰Šé™¤ã•ã‚Œã¾ã—ãŸ")
                continue
            
            old_sessions = old_filtered[stage][day]
            new_sessions = new_filtered[stage][day]
            
            if len(old_sessions) != len(new_sessions):
                print(f"ğŸ“ˆ {stage} - {day}: ã‚»ãƒƒã‚·ãƒ§ãƒ³æ•°ãŒå¤‰æ›´ã•ã‚Œã¾ã—ãŸ ({len(old_sessions)} â†’ {len(new_sessions)})")
            
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®è©³ç´°æ¯”è¼ƒ
            old_titles = {s['title']: s for s in old_sessions}
            new_titles = {s['title']: s for s in new_sessions}
            
            # æ–°ã—ã„ã‚»ãƒƒã‚·ãƒ§ãƒ³
            for title in new_titles:
                if title not in old_titles:
                    print(f"  â• æ–°ã—ã„ã‚»ãƒƒã‚·ãƒ§ãƒ³: {title}")
            
            # å‰Šé™¤ã•ã‚ŒãŸã‚»ãƒƒã‚·ãƒ§ãƒ³
            for title in old_titles:
                if title not in new_titles:
                    print(f"  â– å‰Šé™¤ã•ã‚ŒãŸã‚»ãƒƒã‚·ãƒ§ãƒ³: {title}")
            
            # å¤‰æ›´ã•ã‚ŒãŸã‚»ãƒƒã‚·ãƒ§ãƒ³
            for title in old_titles:
                if title in new_titles:
                    old_session = old_titles[title]
                    new_session = new_titles[title]
                    
                    changes = []
                    if old_session.get('time') != new_session.get('time'):
                        print(f"  ğŸ”„ å¤‰æ›´ã•ã‚ŒãŸã‚»ãƒƒã‚·ãƒ§ãƒ³: {title}")
                        print(f"    - æ™‚é–“: {old_session.get('time', 'N/A')} â†’ {new_session.get('time', 'N/A')}")
                    if old_session.get('description') != new_session.get('description'):
                        if not changes:
                            print(f"  ğŸ”„ å¤‰æ›´ã•ã‚ŒãŸã‚»ãƒƒã‚·ãƒ§ãƒ³: {title}")
                        print(f"    - æ¦‚è¦ãŒå¤‰æ›´ã•ã‚Œã¾ã—ãŸ")
                    if old_session.get('speaker') != new_session.get('speaker'):
                        if not changes:
                            print(f"  ğŸ”„ å¤‰æ›´ã•ã‚ŒãŸã‚»ãƒƒã‚·ãƒ§ãƒ³: {title}")
                        print(f"    - ç™ºè¡¨è€…: {old_session.get('speaker', 'N/A')} â†’ {new_session.get('speaker', 'N/A')}")
                    
                    # å¤‰æ›´ãŒã‚ã£ãŸã‹ã©ã†ã‹ã‚’ãƒãƒ¼ã‚¯
                    if (old_session.get('time') != new_session.get('time') or
                        old_session.get('description') != new_session.get('description') or
                        old_session.get('speaker') != new_session.get('speaker')):
                        changes.append(True)

def preserve_xpost_fields(new_sessions, existing_file):
    """
    æ—¢å­˜ã®sessions.jsonã‹ã‚‰x_postãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’ä¿æŒã—ã¦æ–°ã—ã„ã‚»ãƒƒã‚·ãƒ§ãƒ³ãƒ‡ãƒ¼ã‚¿ã«ãƒãƒ¼ã‚¸ã™ã‚‹
    """
    try:
        with open(existing_file, 'r', encoding='utf-8') as f:
            existing_data = json.load(f)
        
        print("ğŸ”— æ—¢å­˜ã®x_postãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’ä¿æŒä¸­...")
        preserved_count = 0
        
        # ã‚¹ãƒ†ãƒ¼ã‚¸ã”ã¨ã«å‡¦ç†
        for stage in new_sessions:
            if stage not in existing_data:
                continue
                
            # æ—¥ã”ã¨ã«å‡¦ç†
            for day in new_sessions[stage]:
                if day not in existing_data[stage]:
                    continue
                
                new_sessions_list = new_sessions[stage][day]
                existing_sessions_list = existing_data[stage][day]
                
                # æ—¢å­˜ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ã‚¿ã‚¤ãƒˆãƒ«ã§ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹åŒ–
                existing_by_title = {session['title']: session for session in existing_sessions_list}
                
                # æ–°ã—ã„ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«x_postã‚’ä¿æŒ
                for session in new_sessions_list:
                    title = session['title']
                    if title in existing_by_title and 'x_post' in existing_by_title[title]:
                        session['x_post'] = existing_by_title[title]['x_post']
                        preserved_count += 1
                        print(f"  ğŸ”— ä¿æŒ: {stage} - {day} - {title}")
        
        print(f"ğŸ“Š x_postãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ä¿æŒå®Œäº†: {preserved_count}å€‹")
        return new_sessions
        
    except FileNotFoundError:
        print("â„¹ï¸  æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚æ–°è¦ä½œæˆã—ã¾ã™ã€‚")
        return new_sessions
    except json.JSONDecodeError as e:
        print(f"âš ï¸  æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã®è§£æã‚¨ãƒ©ãƒ¼: {e}")
        return new_sessions
    except Exception as e:
        print(f"âš ï¸  x_postãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ä¿æŒä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
        return new_sessions

def main():
    # HTMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
    try:
        with open('/tmp/summit_page.html', 'r', encoding='utf-8') as f:
            html_content = f.read()
    except FileNotFoundError:
        print("HTMLãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚å†å–å¾—ã—ã¾ã™...")
        response = requests.get('https://pages.awscloud.com/summit-japan-2025-aws-expo-booth.html')
        html_content = response.text
        with open('/tmp/summit_page.html', 'w', encoding='utf-8') as f:
            f.write(html_content)
    
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³æƒ…å ±ã‚’æŠ½å‡º
    sessions = extract_sessions_from_html(html_content)
    
    # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
    output_file = '/workspaces/aws-summit-2025-viewer/docs/sessions.json'
    
    # æ—¢å­˜ã®x_postãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’ä¿æŒ
    sessions = preserve_xpost_fields(sessions, output_file)
    
    # æ—¢å­˜ã®sessions.jsonãŒå­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
    if os.path.exists(output_file):
        print("ğŸ“‹ æ—¢å­˜ã®sessions.jsonãŒè¦‹ã¤ã‹ã‚Šã¾ã—ãŸã€‚å·®åˆ†ã‚’ãƒã‚§ãƒƒã‚¯ã—ã¾ã™...")
        
        # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
        with tempfile.NamedTemporaryFile(mode='w', encoding='utf-8', suffix='.json', delete=False) as temp_file:
            json.dump(sessions, temp_file, ensure_ascii=False, indent=2)
            temp_file_path = temp_file.name
        
        try:
            # å·®åˆ†ã‚’ãƒã‚§ãƒƒã‚¯
            has_changes = compare_json_files(output_file, temp_file_path)
            
            if has_changes:
                # è©³ç´°ãªå¤‰æ›´åˆ†æ
                analyze_session_changes(output_file, temp_file_path)
                
                # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ç¢ºèª
                print(f"\nâ“ sessions.jsonã‚’æ›´æ–°ã—ã¾ã™ã‹ï¼Ÿ (y/N): ", end="")
                response = input().strip().lower()
                
                if response in ['y', 'yes']:
                    # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’æœ¬ãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚³ãƒ”ãƒ¼
                    with open(temp_file_path, 'r', encoding='utf-8') as temp_f:
                        with open(output_file, 'w', encoding='utf-8') as output_f:
                            output_f.write(temp_f.read())
                    print(f"âœ… sessions.jsonã‚’æ›´æ–°ã—ã¾ã—ãŸ: {output_file}")
                else:
                    print("âŒ sessions.jsonã®æ›´æ–°ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã—ãŸ")
            else:
                print("â„¹ï¸  æ›´æ–°ã®å¿…è¦ã¯ã‚ã‚Šã¾ã›ã‚“")
                
        finally:
            # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
            os.unlink(temp_file_path)
    else:
        # æ–°è¦ä½œæˆ
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(sessions, f, ensure_ascii=False, indent=2)
        print(f"ğŸ†• æ–°ã—ã„sessions.jsonã‚’ä½œæˆã—ã¾ã—ãŸ: {output_file}")
    
    # çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤º
    print(f"\nğŸ“Š ã‚»ãƒƒã‚·ãƒ§ãƒ³çµ±è¨ˆ:")
    total_sessions = 0
    for stage, days in sessions.items():
        stage_total = sum(len(day_sessions) for day_sessions in days.values())
        total_sessions += stage_total
        print(f"  {stage}: {stage_total}ã‚»ãƒƒã‚·ãƒ§ãƒ³")
    
    print(f"  ç·ã‚»ãƒƒã‚·ãƒ§ãƒ³æ•°: {total_sessions}")

if __name__ == "__main__":
    main()
